{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 Day 3: Data Wrangling with Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikifunctions\n",
    "\n",
    "Dr. Brian Keegan in our INFO department also made a very helpful package through GitHub that allows you to ping the wikipedia API with alot of ease. here is the wikifunctions repository [https://github.com/brianckeegan/wikifunctions]\n",
    "\n",
    "- download wikifunctions.py\n",
    "\n",
    "our code will pull the functions and classes from this file to work with the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import wikifunctions\n",
    "\n",
    "import wikifunctions as wf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revid</th>\n",
       "      <th>parentid</th>\n",
       "      <th>user</th>\n",
       "      <th>anon</th>\n",
       "      <th>userid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>size</th>\n",
       "      <th>sha1</th>\n",
       "      <th>comment</th>\n",
       "      <th>page</th>\n",
       "      <th>date</th>\n",
       "      <th>diff</th>\n",
       "      <th>lag</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>240464</td>\n",
       "      <td>0</td>\n",
       "      <td>12.30.225.xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2001-12-15 21:46:10+00:00</td>\n",
       "      <td>2271</td>\n",
       "      <td>e655c8c7e20feb83d25017cec32d08eee713d130</td>\n",
       "      <td>*</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>2001-12-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>240465</td>\n",
       "      <td>240464</td>\n",
       "      <td>The Epopt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>2001-12-15 22:09:54+00:00</td>\n",
       "      <td>2761</td>\n",
       "      <td>27164baa6abb807c7f20e5dc1323c43503a79348</td>\n",
       "      <td>added a stub about buffalo</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>2001-12-15</td>\n",
       "      <td>490.0</td>\n",
       "      <td>1424.0</td>\n",
       "      <td>0.016481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240466</td>\n",
       "      <td>240465</td>\n",
       "      <td>The Epopt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>2001-12-15 22:10:27+00:00</td>\n",
       "      <td>2762</td>\n",
       "      <td>32c20c60c410376c96d9b1da4570f477483d2d77</td>\n",
       "      <td>*</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>2001-12-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.016863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>240467</td>\n",
       "      <td>240466</td>\n",
       "      <td>Paul Drye</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>2001-12-16 01:16:17+00:00</td>\n",
       "      <td>478</td>\n",
       "      <td>0409290a0ab940c21c2bd3d75963d1b1a7d71e31</td>\n",
       "      <td>Slice out Buffalo, New York and move to [[Buff...</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>2001-12-16</td>\n",
       "      <td>-2284.0</td>\n",
       "      <td>11150.0</td>\n",
       "      <td>0.145914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>240468</td>\n",
       "      <td>240467</td>\n",
       "      <td>The Epopt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>2001-12-16 01:55:32+00:00</td>\n",
       "      <td>479</td>\n",
       "      <td>5703f32d66c0e61ca2391db4045514faffdef655</td>\n",
       "      <td>*</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>2001-12-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2355.0</td>\n",
       "      <td>0.173171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    revid  parentid           user  anon userid                 timestamp  \\\n",
       "0  240464         0  12.30.225.xxx  True      0 2001-12-15 21:46:10+00:00   \n",
       "1  240465    240464      The Epopt   NaN     30 2001-12-15 22:09:54+00:00   \n",
       "2  240466    240465      The Epopt   NaN     30 2001-12-15 22:10:27+00:00   \n",
       "3  240467    240466      Paul Drye   NaN      6 2001-12-16 01:16:17+00:00   \n",
       "4  240468    240467      The Epopt   NaN     30 2001-12-16 01:55:32+00:00   \n",
       "\n",
       "   size                                      sha1  \\\n",
       "0  2271  e655c8c7e20feb83d25017cec32d08eee713d130   \n",
       "1  2761  27164baa6abb807c7f20e5dc1323c43503a79348   \n",
       "2  2762  32c20c60c410376c96d9b1da4570f477483d2d77   \n",
       "3   478  0409290a0ab940c21c2bd3d75963d1b1a7d71e31   \n",
       "4   479  5703f32d66c0e61ca2391db4045514faffdef655   \n",
       "\n",
       "                                             comment     page        date  \\\n",
       "0                                                  *  Buffalo  2001-12-15   \n",
       "1                         added a stub about buffalo  Buffalo  2001-12-15   \n",
       "2                                                  *  Buffalo  2001-12-15   \n",
       "3  Slice out Buffalo, New York and move to [[Buff...  Buffalo  2001-12-16   \n",
       "4                                                  *  Buffalo  2001-12-16   \n",
       "\n",
       "     diff      lag       age  \n",
       "0     NaN      NaN  0.000000  \n",
       "1   490.0   1424.0  0.016481  \n",
       "2     1.0     33.0  0.016863  \n",
       "3 -2284.0  11150.0  0.145914  \n",
       "4     1.0   2355.0  0.173171  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all page revisions\n",
    "\n",
    "rev_df = wf.get_all_page_revisions(\"Buffalo\")\n",
    "rev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2015-07-01    937\n",
       "2015-07-02    932\n",
       "2015-07-03    825\n",
       "2015-07-04    824\n",
       "2015-07-05    852\n",
       "Name: views, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get pageviews\n",
    "pvs1 = wf.get_pageviews(\"Denver Broncos\")\n",
    "pvs1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get current page content\n",
    "page_content = wf.get_page_raw_content(\"Will Smith\")\n",
    "page_content.find('shortdescription nomobile noexcerpt noprint searchaux')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Will Smith',\n",
       " 'af': 'Will Smith',\n",
       " 'am': '·ãä·àç ·àµ·àö·ãù',\n",
       " 'an': 'Will Smith',\n",
       " 'ar': 'ŸàŸäŸÑ ÿ≥ŸÖŸäÿ´',\n",
       " 'arz': 'ŸàŸäŸÑ ÿ≥ŸÖŸäÿ´',\n",
       " 'ast': 'Will Smith',\n",
       " 'az': 'Vill Smit',\n",
       " 'azb': 'Ÿà€åŸÑ ÿßÿ≥ŸÖ€åÿ™',\n",
       " 'be': '–£—ñ–ª –°–º—ñ—Ç',\n",
       " 'bg': '–£–∏–ª –°–º–∏—Ç',\n",
       " 'bh': '‡§µ‡§ø‡§≤ ‡§∏‡•ç‡§Æ‡§ø‡§•',\n",
       " 'bn': '‡¶â‡¶á‡¶≤ ‡¶∏‡ßç‡¶Æ‡¶ø‡¶•',\n",
       " 'br': 'Will Smith',\n",
       " 'bs': 'Will Smith',\n",
       " 'ca': 'Will Smith',\n",
       " 'ceb': 'Will Smith',\n",
       " 'ckb': 'Ÿà€å⁄µ ÿ≥ŸÖ€åÿ™',\n",
       " 'co': 'Will Smith',\n",
       " 'cs': 'Will Smith',\n",
       " 'cv': '–£–∏–ª–ª –°–º–∏—Ç',\n",
       " 'cy': 'Will Smith',\n",
       " 'da': 'Will Smith',\n",
       " 'de': 'Will Smith',\n",
       " 'el': 'ŒìŒøœÖŒØŒª Œ£ŒºŒπŒ∏',\n",
       " 'eo': 'Will Smith',\n",
       " 'es': 'Will Smith',\n",
       " 'et': 'Will Smith',\n",
       " 'eu': 'Will Smith',\n",
       " 'fa': 'Ÿà€åŸÑ ÿßÿ≥ŸÖ€åÿ™',\n",
       " 'fi': 'Will Smith',\n",
       " 'fo': 'Will Smith',\n",
       " 'fr': 'Will Smith',\n",
       " 'frp': 'Will Smith',\n",
       " 'fy': 'Will Smith',\n",
       " 'ga': 'Will Smith',\n",
       " 'gd': 'Will Smith',\n",
       " 'gl': 'Will Smith',\n",
       " 'got': 'êçÖêåπêåªêåª êçÉêåºêåπêå∏',\n",
       " 'gv': 'Will Smith',\n",
       " 'ha': 'Will Smith',\n",
       " 'he': \"◊ï◊ô◊ú ◊°◊û◊ô◊™'\",\n",
       " 'hi': '‡§µ‡§ø‡§≤ ‡§∏‡•ç‡§Æ‡§ø‡§•',\n",
       " 'hr': 'Will Smith',\n",
       " 'ht': 'Will Smith',\n",
       " 'hu': 'Will Smith',\n",
       " 'hy': '’à÷Ç’´’¨ ’ç’¥’´’©',\n",
       " 'hyw': '’à÷Ç’´’¨’¨ ’ç’¥’´’©',\n",
       " 'id': 'Will Smith',\n",
       " 'io': 'Will Smith',\n",
       " 'it': 'Will Smith',\n",
       " 'ja': '„Ç¶„Ç£„É´„Éª„Çπ„Éü„Çπ',\n",
       " 'jv': 'Will Smith',\n",
       " 'ka': '·É£·Éò·Éö ·É°·Éõ·Éò·Éó·Éò',\n",
       " 'kk': '–£–∏–ª–ª –°–º–∏—Ç',\n",
       " 'kn': '‡≤µ‡≤ø‡≤≤‡≥ç ‡≤∏‡≥ç‡≤Æ‡≤ø‡≤§‡≥ç',\n",
       " 'ko': 'Ïúå Ïä§ÎØ∏Ïä§',\n",
       " 'ks': 'ŸàŸêŸÑ ÿ≥ŸêŸÖŸêÿ™⁄æ',\n",
       " 'ku': 'Will Smith',\n",
       " 'ky': '–£–∏–ª–ª –°–º–∏—Ç',\n",
       " 'la': 'Will Smith',\n",
       " 'lb': 'Will Smith',\n",
       " 'lmo': 'Will Smith',\n",
       " 'lt': 'Will Smith',\n",
       " 'lv': 'Vills Smits',\n",
       " 'mg': 'Will Smith',\n",
       " 'mk': '–í–∏–ª –°–º–∏—Ç',\n",
       " 'ml': '‡¥µ‡¥ø‡µΩ ‡¥∏‡µç‡¥Æ‡¥ø‡¥§‡µç‡¥§‡µç',\n",
       " 'mn': '–í–∏–ª–ª –°–º–∏—Ç',\n",
       " 'mr': '‡§µ‡§ø‡§≤ ‡§∏‡•ç‡§Æ‡§ø‡§•',\n",
       " 'ms': 'Will Smith',\n",
       " 'my': '·Äù·ÄÆ·Äú·Ä∫ ·ÄÖ·Äô·ÄÖ·Ä∫',\n",
       " 'ne': '‡§µ‡§ø‡§≤ ‡§∏‡•ç‡§Æ‡§ø‡§•',\n",
       " 'nl': 'Will Smith',\n",
       " 'nn': 'Will Smith',\n",
       " 'nb': 'Will Smith',\n",
       " 'nup': 'Larry Bird',\n",
       " 'oc': 'Will Smith',\n",
       " 'pa': '‡®µ‡®ø‡®≤ ‡®∏‡®Æ‡®ø‡®•',\n",
       " 'pl': 'Will Smith',\n",
       " 'pms': 'Will Smith',\n",
       " 'pt': 'Will Smith',\n",
       " 'qu': 'Will Smith',\n",
       " 'ro': 'Will Smith',\n",
       " 'ru': '–°–º–∏—Ç, –£–∏–ª–ª',\n",
       " 'rw': 'Will Smith',\n",
       " 'sah': '–£–∏–ª–ª –°–º–∏—Ç',\n",
       " 'sc': 'Will Smith',\n",
       " 'sh': 'Will Smith',\n",
       " 'simple': 'Will Smith',\n",
       " 'sk': 'Will Smith',\n",
       " 'sl': 'Will Smith',\n",
       " 'sq': 'Will Smith',\n",
       " 'sr': '–í–∏–ª –°–º–∏—Ç',\n",
       " 'srn': 'Will Smith',\n",
       " 'sv': 'Will Smith',\n",
       " 'sw': 'Will Smith',\n",
       " 'ta': '‡Æµ‡Æø‡Æ≤‡Øç ‡Æö‡Æø‡ÆÆ‡Æø‡Æ§‡Øç',\n",
       " 'te': '‡∞µ‡∞ø‡∞≤‡±ç ‡∞∏‡±ç‡∞Æ‡∞ø‡∞§‡±ç',\n",
       " 'tg': '–£–∏–ª–ª –°–º–∏—Ç',\n",
       " 'th': '‡∏ß‡∏¥‡∏•‡∏•‡πå ‡∏™‡∏°‡∏¥‡∏ò',\n",
       " 'tr': 'Will Smith',\n",
       " 'tt': '–£–∏–ª–ª –°–º–∏—Ç',\n",
       " 'uk': '–í—ñ–ª–ª –°–º—ñ—Ç',\n",
       " 'uz': 'Will Smith',\n",
       " 'vi': 'Will Smith',\n",
       " 'war': 'Will Smith',\n",
       " 'wuu': 'Â®ÅÂ∞î¬∑Âè≤ÂØÜÊñØ',\n",
       " 'xmf': '·É£·Éò·Éö ·É°·Éõ·Éò·Éó·Éò',\n",
       " 'yo': 'Will Smith',\n",
       " 'zh': 'Â®ÅÁàæ¬∑Âè≤ÂØÜÊñØ',\n",
       " 'zh-yue': 'ÈüãÂè≤ÂØÜÂ§´'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get interlanguage links\n",
    "\n",
    "ill_df = wf.get_interlanguage_links(\"Will Smith\")\n",
    "ill_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### as page revisions df to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_df.to_csv(\"class_data/page_revisions_buffalo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most straight-forward way to import a library in Python\n",
    "import requests\n",
    "\n",
    "# BeautifulSoup is a module inside the \"bs4\" library, we only import the BeautifulSoup module\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# We import pandas but give the library a shortcut alias \"pd\" since we will call its functions so much\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading an HTML table into Python\n",
    "\n",
    "[The Numbers](http://www.the-numbers.com) is a popular source of data about movies' box office revenue numbers. Their daily domestic charts are HTML tables with the top-grossing movies for each day of the year, going back for several years. This [table](https://www.the-numbers.com/box-office-chart/daily/2018/12/25) for Christmas day in 2018 has coluns for the current week's ranking, previous week's ranking, name of movie, distributor, gross, change over the previous week, number of theaters, revenue per theater, total gross, and number of days since release. This looks like a fairly straightforward table that could be read directly into data frame-like structure.\n",
    "\n",
    "Using the Inspect tool, we can see the table exists as a `<table border=\"0\" ... align=\"CENTER\">` element with child tags like `<tbody>` and `<tr>` (table row). Each `<tr>` has `<td>` which defines each of the cells and their content. For more on how HTML defines tables, check out [this tutoral](https://www.w3schools.com/html/html_tables.asp).\n",
    "\n",
    "Using `requests` and `BeautifulSoup` we would get this webpage's HTML, turn it into soup, and then find the table (`<table>`) or the table rows (`<tr>`) and pull out their content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the request\n",
    "\n",
    "#this is just asking for information stuff from the website -- it can kind of be whatever\n",
    "\n",
    "user_agent = {'user-agent':'info-2201/0.0 Web Data Science, laurie.jones@colorado.edu'}\n",
    "\n",
    "xmas_bo_raw = requests.get( 'https://www.the-numbers.com/box-office-chart/daily/2018/12/25', headers = user_agent).text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn into soup, specify the HTML parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .find_all to retrieve all the tables in the page\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out there are two tables on the page, the first is a baby table consisting of the \"Previous Chart\", \"Chart Index\", and \"Next Chart\" at the top. We want the second table with all the data: `xmas_bo_tables[1]` returns the second chart (remember that Python is 0-indexed, so the first chart is at `xmas_bo_tables[0]`). With this table identified, we can do a second `find_all` to get the table rows inside it and we save it as `xmas_bo_trs`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pandas`'s `read_html`\n",
    "That was a good amount of work just to get this simple HTML table into Python. But it was important to cover how table elements moved from a string in `requests`, into a soup object from `BeautifulSoup`. into a list of data, and finally into `pandas`. \n",
    "\n",
    "`pandas` also has powerful functionality for reading tables directly from HTML. If we convert the soup of the first table (`xmas_bo_tables[1]`) back into a string, `pandas` can read it directly into a table. \n",
    "\n",
    "There are a few ideosyncracies here, the result is a list of dataframes‚Äîeven if there's only a single table/dataframe‚Äîso we need to return the first (and only) element of this list. This is why there's a `[0]` at the end and the `.head()` is just to show the first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the string of the first table into pd.read_html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column names got lumped in as rows, but we can fix this as well with the `read_html` function by passing the row index where the column lives. In this case, it is the first row, so we pass `header=0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just ge the head of the df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
